{
  "repo_notes": [
    {
      "content": "Skill Scanner is a security analysis tool that detects threats in AI Agent Skills packages. It uses a defense-in-depth approach with six independent analyzer engines: pattern-based (YAML regex + YARA), Python AST dataflow analysis, LLM semantic analysis (supporting Anthropic, OpenAI, LiteLLM, Google GenAI, AWS Bedrock, GCP Vertex AI, Azure OpenAI), a meta-analyzer for false-positive filtering, VirusTotal hash-based malware detection, and Cisco AI Defense cloud-based threat detection. The threat taxonomy aligns with Cisco Integrated AI Security Framework (AITech codes)",
      "author": "Maintainer"
    },
    {
      "content": "The codebase is organized into these key areas:\n- skill_scanner/cli/ — CLI entry point (argparse-based) with commands: scan, scan-all, list-analyzers, validate-rules, generate-policy, configure-policy (Textual TUI)\n- skill_scanner/api/ — FastAPI REST API server with endpoints for single scan, upload scan, batch scan, health, and analyzer listing\n- skill_scanner/core/ — Core scanning engine: scanner.py (SkillScanner orchestrator), loader.py (SKILL.md parser), models.py (Pydantic data models), scan_policy.py (policy engine)\n- skill_scanner/core/analyzers/ — All analyzer implementations: static.py, behavioral_analyzer.py, llm_analyzer.py, pipeline_analyzer.py, meta_analyzer.py, virustotal_analyzer.py, aidefense_analyzer.py, trigger_analyzer.py, bytecode_analyzer.py\n- skill_scanner/core/static_analysis/ — Python AST analysis: cfg/, dataflow/, taint/, bash_taint_tracker.py, semantic/\n- skill_scanner/core/reporters/ — Output formatters: json_reporter.py, sarif_reporter.py, markdown_reporter.py, table_reporter.py\n- skill_scanner/data/ — Detection rules: packs/core/signatures/ (90+ regex rules), packs/core/yara/ (14 YARA rule files), packs/core/python/ (12 Python check modules), prompts/ (LLM prompt templates), default/strict/permissive policy presets\n- skill_scanner/threats/ — Threat taxonomy: threats.py (ThreatMapping), cisco_ai_taxonomy.py (AITech codes)\n- skill_scanner/hooks/ — Git pre-commit hook integration\n- skill_scanner/config/ — Configuration management, environment variables, constants",
      "author": "Maintainer"
    },
    {
      "content": "Documentation should prioritize practical usage: installation via uv or pip, CLI commands with real examples, Python SDK programmatic usage, REST API integration, CI/CD pipeline setup with GitHub Actions and SARIF output, and scan policy customization. The examples/ directory contains 8 runnable Python scripts covering basic scanning, advanced multi-analyzer setups, batch scanning, behavioral analysis, LLM analysis, API usage, CI/CD integration, and programmatic usage. The evals/ directory contains a benchmarking framework with 10+ eval skills across threat categories (backdoor, command-injection, data-exfiltration, obfuscation, prompt-injection, etc.) and 10 policy presets for policy benchmarking. The docs/ directory has detailed markdown docs on architecture, each analyzer, scan policies, the API server, threat taxonomy, and development setup.",
      "author": "Maintainer"
    },
    {
      "content": "Key integration points: The package is published as cisco-ai-skill-scanner on PyPI. The scanner supports configurable scan policies with three presets (strict, balanced, permissive) and a Textual-based TUI for interactive policy configuration. Output formats include summary (colored console), JSON, Markdown, ASCII table, and SARIF 2.1.0 for GitHub Code Scanning integration.",
      "author": "Maintainer"
    },
    {
      "content": "The following directories are internal development infrastructure and should NOT have dedicated wiki pages: evals/ (benchmark framework, eval skills, policy presets — mention briefly in Development section only), .local_benchmark/ (local checkpoint data — do not document), .cursor/ and .devin/ (editor and wiki config — do not document), .github/ISSUE_TEMPLATE/ and .github/PULL_REQUEST_TEMPLATE.md (standard GitHub templates — do not document). Focus documentation effort on the skill_scanner/ package, examples/, docs/, and top-level config files (pyproject.toml, .env.example).",
      "author": "Maintainer"
    }
  ],
  "pages": [
    {
      "title": "Home",
      "purpose": "High-level overview of Skill Scanner: what it is, what problems it solves, key features (multi-engine detection, 6 analyzers, 4 security framework alignments), supported skill formats (OpenAI Codex, Cursor Agent Skills), and navigation guide to the rest of the wiki. Reference README.md and pyproject.toml."
    },
    {
      "title": "Key Concepts and Security Model",
      "purpose": "Explain foundational concepts: what AI Agent Skills are (SKILL.md format with YAML front matter, metadata, instructions, supporting files), why they pose security risks (arbitrary code execution, transitive trust, privilege escalation), the difference between skills and MCP servers, the defense-in-depth detection philosophy, the threat model, security best practices (recommended analyzer combinations for dev/staging/prod, binary handling rationale, remediation workflow), and limitations of each analyzer. Reference docs/, skill_scanner/threats/, docs/binary-handling.md, docs/remote-skills-analysis.md.",
      "parent": "Home"
    },
    {
      "title": "Quick Start",
      "purpose": "Step-by-step getting started guide: install with uv pip install cisco-ai-skill-scanner or pip, run your first scan with skill-scanner scan <path>, interpret the output, enable additional analyzers (--use-behavioral, --use-llm), set up environment variables for LLM API keys. Include real command examples and expected output. Reference docs/quickstart.md and README.md.",
      "parent": "Home"
    },
    {
      "title": "User Guide",
      "purpose": "Parent page for all user-facing documentation. Overview of the four ways to use Skill Scanner: CLI, Python SDK, REST API, and pre-commit hooks. Brief summary of each with links to child pages.",
      "parent": "Home"
    },
    {
      "title": "Installation and Configuration",
      "purpose": "Comprehensive installation guide: uv and pip installation, optional extras ([bedrock], [vertex], [azure], [supply-chain], [all]), all environment variables (SKILL_SCANNER_LLM_API_KEY, SKILL_SCANNER_LLM_MODEL, SKILL_SCANNER_LLM_PROVIDER, VIRUSTOTAL_API_KEY, AI_DEFENSE_API_KEY, AWS_REGION, AZURE_OPENAI_ENDPOINT, etc.), .env file setup using .env.example, configuration priority (CLI args > env vars > defaults), and LLM provider configuration for each supported provider (Anthropic, OpenAI, LiteLLM, Google GenAI, Bedrock, Vertex AI, Azure). Reference skill_scanner/config/config.py, .env.example.",
      "parent": "User Guide"
    },
    {
      "title": "CLI Usage",
      "purpose": "Complete CLI reference with examples for every command: (1) skill-scanner scan <dir> with all flags (--format, --output, --fail-on-findings, --use-behavioral, --use-llm, --use-virustotal, --use-aidefense, --enable-meta, --use-trigger, --policy, --custom-rules, --llm-provider, --llm-consensus-runs), (2) skill-scanner scan-all <dir> with --recursive and --check-overlap, (3) skill-scanner list-analyzers, (4) skill-scanner validate-rules, (5) skill-scanner generate-policy with --preset and -o, (6) skill-scanner configure-policy TUI. Show real command examples and expected outputs for each. Reference skill_scanner/cli/cli.py.",
      "parent": "User Guide"
    },
    {
      "title": "Python SDK",
      "purpose": "How to use Skill Scanner as a Python library: importing SkillScanner, scan_skill(), scan_directory(), load_skill(), configuring analyzers programmatically (StaticAnalyzer, BehavioralAnalyzer, LLMAnalyzer, etc.), accessing ScanResult fields (is_safe, findings, max_severity, scan_duration_seconds), filtering findings by severity and category, custom analyzer configurations, and working with Finding objects. Include code examples from examples/programmatic_usage.py and examples/basic_scan.py. Reference skill_scanner/core/scanner.py, skill_scanner/core/models.py.",
      "parent": "User Guide"
    },
    {
      "title": "API Server",
      "purpose": "Complete REST API documentation: starting the server (skill-scanner-api --host --port --reload), all endpoints with request/response schemas (GET /, GET /health, POST /scan with ScanRequest body, POST /scan-upload for ZIP files, POST /scan-batch for background batch scans, GET /scan-batch/{id} for status, GET /analyzers), authentication considerations, Docker deployment example, and API usage examples with curl and httpx. Reference skill_scanner/api/router.py, skill_scanner/api/api_server.py, docs/api-server.md, examples/api_usage.py.",
      "parent": "User Guide"
    },
    {
      "title": "Scan Policies Overview",
      "purpose": "Introduction to the scan policy system: what scan policies are and why they exist, the three built-in presets (strict, balanced, permissive) with a side-by-side comparison table showing how they differ across every dimension, how to get started quickly with presets (skill-scanner scan --policy strict), generating a baseline YAML with skill-scanner generate-policy --preset balanced -o my_policy.yaml, loading custom policies with --policy my_policy.yaml, merge behavior (custom YAML merges on top of defaults so you only need to specify changed sections), and using the configure-policy TUI for interactive editing. Include the preset comparison table showing key differences: benign dotfiles count (strict: 6, balanced: 35, permissive: 83+), max file count (50/100/500), max file size (2MB/5MB/20MB), zerowidth thresholds, command safety tier assignments, severity overrides, and disabled rules. Reference skill_scanner/core/scan_policy.py, skill_scanner/data/default_policy.yaml, skill_scanner/data/strict_policy.yaml, skill_scanner/data/permissive_policy.yaml, docs/scan-policy.md.",
      "parent": "User Guide"
    },
    {
      "title": "Custom Policy Configuration",
      "purpose": "Exhaustive reference for every configurable knob in a scan policy YAML file, organized by section. This is the deep-dive page for users who want to build custom policies. Cover: (1) METADATA — policy_name, policy_version, preset_base fields; (2) HIDDEN FILES (hidden_files) — benign_dotfiles list (dotfiles not flagged, others trigger HIDDEN_DATA_FILE), benign_dotdirs list (dotdirs not flagged, others trigger HIDDEN_DATA_DIR); (3) PIPELINE ANALYSIS (pipeline) — known_installer_domains (domains where curl|sh is demoted to LOW), benign_pipe_targets (regex patterns for suppressed pipelines), doc_path_indicators (path segments marking documentation for lower severity); (4) RULE SCOPING (rule_scoping) — skillmd_and_scripts_only (rules only on SKILL.md + scripts), skip_in_docs (rules not in doc dirs), code_only (rules only on .py/.sh etc.), doc_path_indicators (dir names as docs), doc_filename_patterns (regex for educational filenames); (5) CREDENTIALS (credentials) — known_test_values (exact matches suppressed as test creds), placeholder_markers (substrings for placeholder filtering); (6) SYSTEM CLEANUP (system_cleanup) — safe_rm_targets (allowed rm -rf targets); (7) FILE CLASSIFICATION (file_classification) — inert_extensions, structured_extensions, archive_extensions, code_extensions and how each affects scanning; (8) FILE LIMITS (file_limits) — max_file_count (default 100, triggers EXCESSIVE_FILE_COUNT), max_file_size_bytes (default 5MB, triggers OVERSIZED_FILE), max_reference_depth (default 5), max_name_length (default 64), max_description_length (default 1024), min_description_length (default 20); (9) ANALYSIS THRESHOLDS (analysis_thresholds) — zerowidth_threshold_with_decode (default 50), zerowidth_threshold_alone (default 200), analyzability_low_risk (default 90), analyzability_medium_risk (default 70); (10) SENSITIVE FILES (sensitive_files) — patterns list (regex that upgrades pipeline taint to SENSITIVE_DATA); (11) COMMAND SAFETY (command_safety) — safe_commands, caution_commands, risky_commands, dangerous_commands tier lists and dangerous_arg_patterns regex list, how tiers affect code_execution findings; (12) ANALYZERS (analyzers) — static/bytecode/pipeline booleans to enable/disable built-in analyzers; (13) SEVERITY OVERRIDES (severity_overrides) — list of rule_id/severity/reason to override finding severity per rule; (14) DISABLED RULES (disabled_rules) — list of rule IDs completely suppressed. All tunable parameters live in these named policy sections (file_limits, analysis_thresholds, pipeline, file_classification, etc.); there is no separate rule_properties or per-rule override layer. Also cover the CONFIGURE-POLICY TUI walkthrough: how to launch (skill-scanner configure-policy -o policy.yaml), the Textual-based UI with radio buttons for preset selection, Input fields for numeric limits, Edit list modals for sets/lists (one item per line), checkboxes for analyzer toggles, the SetEditorScreen for editing collections, and Save Policy to export. All knobs are configurable via these named policy sections—no separate advanced rule-tuning screen. Include practical examples: a CI pipeline policy (strict file limits, HIGH severity for binaries/archives), an internal tooling policy (relaxed limits, trusted domains), a compliance audit policy (empty allowlists, maximum visibility). Reference the 10 eval policies in evals/policies/ as real-world examples (01_baseline, 02_strict, 03_permissive, 04_compliance_audit, 05_ci_pipeline, 06_internal_tooling, 07_no_pipeline_analysis, 08_yara_wide_open, 09_cred_heavy, 10_max_sensitivity). Reference skill_scanner/core/scan_policy.py, skill_scanner/cli/policy_tui.py, docs/scan-policy.md, evals/policies/.",
      "parent": "Scan Policies Overview"
    },
    {
      "title": "Architecture",
      "purpose": "Architecture overview and system design philosophy. Show the four layers: Entry Points (CLI, API, pre-commit, SDK), Core Orchestration (SkillScanner, SkillLoader, Config), Analysis Engines (6 analyzers), and Output Reporting (5 reporters). Cover the modular analyzer design, defense-in-depth approach, configurable pipeline, extensible plugin architecture, and relationships between components. Include the data models: Skill, Finding, ScanResult, ScanPolicy, Severity enum, ThreatCategory enum. Cover SKILL.md parsing with python-frontmatter, ZIP archive handling, and the SkillLoader class. Show how data flows from skill input through loading, analysis, aggregation, optional meta-analysis, to result construction. Reference skill_scanner/core/scanner.py, skill_scanner/core/models.py, skill_scanner/core/loader.py, docs/architecture.md.",
      "parent": "Home"
    },
    {
      "title": "Scanning Pipeline",
      "purpose": "Detailed walkthrough of the scanning pipeline stages: (1) Loading — SkillLoader parses SKILL.md with python-frontmatter, extracts metadata and files, handles ZIP archives; (2) Static Analysis — 6-pass architecture (metadata validation, instruction scanning, code scanning, cross-validation, file existence, YARA); (3) Parallel Analysis — behavioral AST, LLM semantic, external APIs run concurrently; (4) Aggregation — deduplication by threat_category+description hash, severity normalization; (5) Meta-Analysis — optional LLM-based false positive filtering; (6) Result Construction — ScanResult with is_safe, findings, max_severity, scan_duration_seconds. Reference skill_scanner/core/scanner.py, skill_scanner/core/loader.py.",
      "parent": "Architecture"
    },
    {
      "title": "Analyzers",
      "purpose": "Parent page listing all analyzer engines with a capabilities matrix: which are always available vs require API keys, detection methods, primary targets, and configuration flags. Overview of the Analyzer base interface and how analyzers produce Finding objects. Include the AnalyzerFactory and how analyzers are built from CLI flags and policy. Reference skill_scanner/core/analyzer_factory.py.",
      "parent": "Architecture"
    },
    {
      "title": "Static Analyzer",
      "purpose": "Deep dive into the StaticAnalyzer: YAML regex rules (data/packs/core/signatures/ with 90+ patterns organized by category — prompt_injection, command_injection, path_traversal, sql_injection, hardcoded_secrets, obfuscation, etc.), YARA rule files (14 rules covering prompt injection, command injection, credential harvesting, code execution, SQL injection, obfuscation, autonomy abuse, capability inflation, tool chaining, system manipulation, embedded binary detection), the 6-pass scanning architecture, how rules are matched against different file types, custom rules support via --custom-rules, rule validation with validate-rules command, and the pipeline analyzer for shell command taint analysis. Reference skill_scanner/core/analyzers/static.py, skill_scanner/core/analyzers/pipeline_analyzer.py, skill_scanner/data/packs/core/signatures/, skill_scanner/data/packs/core/yara/, skill_scanner/core/rules/.",
      "parent": "Analyzers"
    },
    {
      "title": "Behavioral Analyzer",
      "purpose": "Deep dive into Python AST dataflow analysis: how the behavioral analyzer works without executing code, components (AST parser, CFG builder, forward dataflow tracker, taint tracker, interprocedural analysis, cross-file analysis, name resolver, type analysis, bash taint tracker), how taint sources and sinks are defined, detection of data exfiltration paths, command injection through eval/exec, and multi-file analysis. Include examples of what it catches that static analysis misses. Reference skill_scanner/core/analyzers/behavioral_analyzer.py, skill_scanner/core/static_analysis/, docs/behavioral-analyzer.md.",
      "parent": "Analyzers"
    },
    {
      "title": "LLM Analyzer",
      "purpose": "Deep dive into LLM-as-a-judge analysis: how SKILL.md content is sent to LLMs for semantic analysis, supported providers (Anthropic Claude, OpenAI GPT, LiteLLM, Google GenAI, AWS Bedrock, GCP Vertex AI, Azure OpenAI), prompt construction and templates in skill_scanner/data/prompts/, structured output parsing, consensus mode with --llm-consensus-runs, threat-to-AITech taxonomy mapping, provider-specific configuration, and cost/latency considerations. Reference skill_scanner/core/analyzers/llm_analyzer.py, skill_scanner/core/analyzers/llm_prompt_builder.py, skill_scanner/data/prompts/, docs/llm-analyzer.md.",
      "parent": "Analyzers"
    },
    {
      "title": "Meta-Analyzer and External Analyzers",
      "purpose": "Combined documentation for the meta-analyzer and external service analyzers: (1) Meta-Analyzer — second-pass LLM analysis for false positive filtering, consolidation of redundant findings, severity normalization, 64% noise reduction, --enable-meta flag, SKILL_SCANNER_META_LLM_* env vars; (2) VirusTotal Analyzer — hash-based malware detection for binary files, VIRUSTOTAL_API_KEY setup, file upload option, --use-virustotal; (3) AI Defense Analyzer — Cisco cloud-based threat detection, AI_DEFENSE_API_KEY/AI_DEFENSE_API_URL setup, default rules, --use-aidefense; (4) Trigger Analyzer — description specificity checking, --use-trigger; (5) Bytecode Analyzer — .pyc integrity checking. Reference skill_scanner/core/analyzers/meta_analyzer.py, skill_scanner/core/analyzers/virustotal_analyzer.py, skill_scanner/core/analyzers/aidefense_analyzer.py, skill_scanner/core/analyzers/trigger_analyzer.py, skill_scanner/core/analyzers/bytecode_analyzer.py, docs/meta-analyzer.md, docs/aidefense-analyzer.md.",
      "parent": "Analyzers"
    },
    {
      "title": "Writing Custom Rules",
      "purpose": "Guide for extending Skill Scanner's detection capabilities by authoring custom YAML signature rules and YARA rules. Cover two rule systems: (1) YAML SIGNATURE RULES — the rule schema with all fields: id (unique rule identifier like COMMAND_INJECTION_EVAL), category (one of ThreatCategory values: prompt_injection, command_injection, data_exfiltration, obfuscation, hardcoded_secrets, etc.), severity (CRITICAL/HIGH/MEDIUM/LOW/INFO), patterns (list of Python re-compatible regex strings), exclude_patterns (optional regexes that suppress false-positive matches), file_types (optional list like [python], [markdown], [bash], [binary], [manifest] — omit for all types), description (finding text), remediation (optional fix guidance). Show a complete example rule YAML entry. Explain how RuleLoader in skill_scanner/core/rules/patterns.py loads rules, compiles patterns with re.compile(), and matches line-by-line with multiline support. Cover validation with skill-scanner validate-rules --rules-file path/to/custom.yaml which checks YAML syntax, required fields, and regex compilation. Note that custom YAML rules files are currently validated only and not loaded at scan time via CLI. (2) YARA RULES — the .yara file structure with meta block (author, description, classification, threat_type, severity), strings block (regex patterns with /pattern/i, hex byte sequences with { 7F 45 4C 46 }), and condition block. Show how to write a YARA rule for text patterns vs binary detection. Explain the --custom-rules /path/to/dir flag which replaces the built-in YARA rules directory entirely (not merged). Cover how YaraScanner in skill_scanner/core/rules/yara_scanner.py compiles rules with yara-x (one namespace per file), and how YARA metadata maps to Finding fields. Include a comparison table: YAML rules use Python re engine for line-by-line text matching with exclude patterns, while YARA rules use the yara-x engine for both text and binary pattern matching with hex strings. Reference skill_scanner/data/packs/core/signatures/ for the 90+ built-in YAML rules, skill_scanner/data/packs/core/yara/ for the 14 built-in YARA rule files, skill_scanner/core/rules/patterns.py, skill_scanner/core/rules/yara_scanner.py.",
      "parent": "Analyzers"
    },
    {
      "title": "Threat Taxonomy",
      "purpose": "Complete threat taxonomy documentation: all 11 threat categories with severity levels (CRITICAL: Command/Code Injection AITech-9.1.4, Data Exfiltration AITech-8.2/8.2.3, Hardcoded Secrets AITech-8.2; HIGH: Prompt Injection AITech-1.1/1.2, Transitive Trust AITech-1.2, Tool Chaining AITech-8.2.3; MEDIUM: Autonomy Abuse AITech-9.1, Tool/Permission Abuse AITech-12.1; LOW: Social Engineering AITech-2.1, Resource Abuse AITech-13.3.2, Obfuscation), the Cisco Integrated AI Security Framework mapping, MITRE ATLAS alignment, OWASP LLM Top 10 mapping, NIST AI RMF references, ThreatMapping class, and how findings are categorized. Reference skill_scanner/threats/threats.py, skill_scanner/threats/cisco_ai_taxonomy.py, docs/threat-taxonomy.md.",
      "parent": "Architecture"
    },
    {
      "title": "Development",
      "purpose": "Parent page for development documentation. Overview of the development workflow, tooling (uv, pytest, ruff, mypy), project structure, and how to contribute to the project.",
      "parent": "Home"
    },
    {
      "title": "Development Setup and Testing",
      "purpose": "How to set up a development environment and run tests: prerequisites (Python 3.10+, uv), cloning the repo, uv sync for dependency installation, pre-commit install, code quality tools (ruff linting and formatting, mypy type checking). Testing infrastructure: pytest configuration, test markers (slow, integration, requires_llm, e2e), unit test organization in tests/ directory, test fixtures in conftest.py, running specific test suites, coverage reporting with Codecov, and how to write new tests. Reference docs/developing.md, pyproject.toml, .pre-commit-config.yaml, tests/.",
      "parent": "Development"
    },
    {
      "title": "CI/CD Setup and Integration",
      "purpose": "Complete CI/CD guide: (1) GitHub Actions workflows — python-tests.yml (lint with pre-commit, test across Python 3.10-3.12, benchmark, coverage with Codecov, pip-audit, liccheck), integration-tests.yml (LLM/VT/AI Defense tests with GitHub secrets, triggered by label or manual), release.yml (PyPI publishing with trusted publishing); (2) Integrating skill-scanner into your own CI/CD — using --fail-on-findings for build gates, SARIF output for GitHub Code Scanning integration, JSON output for automation, exit codes; (3) Docker deployment example; (4) Batch scanning in CI with scan-all. Include real workflow YAML examples. Reference .github/workflows/, examples/integration_example.py, docs/api-server.md.",
      "parent": "Development"
    },
    {
      "title": "Examples and How-To Guides",
      "purpose": "Walkthrough of all 8 example scripts in examples/ with code and expected outputs: (1) basic_scan.py — simplest single-skill scan with StaticAnalyzer; (2) programmatic_usage.py — SDK usage with custom config and finding grouping by category/severity; (3) advanced_scanning.py — multi-analyzer setup with severity filtering and JSON/Markdown output; (4) batch_scanning.py — recursive directory scanning with JSON reports and severity breakdown; (5) behavioral_analyzer_example.py — static vs behavioral vs combined comparison; (6) llm_analyzer_example.py — LLM analysis with Claude/GPT, static vs LLM comparison; (7) api_usage.py — REST API usage with httpx (health, scan, upload, batch); (8) integration_example.py — CI/CD patterns with fail-on-critical, fail-on-high, fail-on-findings. Reference examples/.",
      "parent": "Home"
    },
    {
      "title": "Reference",
      "purpose": "Parent page for reference documentation. Index of all reference materials: configuration options, API endpoints, output formats, dependencies, CLI commands, and detection rule formats.",
      "parent": "Home"
    },
    {
      "title": "Configuration Reference",
      "purpose": "Complete reference table of all configuration options: every environment variable with description, default value, and what it enables (SKILL_SCANNER_LLM_API_KEY, SKILL_SCANNER_LLM_MODEL, SKILL_SCANNER_LLM_PROVIDER, SKILL_SCANNER_LLM_BASE_URL, SKILL_SCANNER_LLM_API_VERSION, SKILL_SCANNER_META_LLM_*, VIRUSTOTAL_API_KEY, VIRUSTOTAL_UPLOAD_FILES, AI_DEFENSE_API_KEY, AI_DEFENSE_API_URL, ENABLE_*_ANALYZER, AWS_REGION, AWS_PROFILE); every CLI flag; scan policy YAML schema with all sections; .skill_scannerrc format; and configuration precedence (CLI > env > defaults). Reference skill_scanner/config/config.py, skill_scanner/config/constants.py, skill_scanner/core/scan_policy.py.",
      "parent": "Reference"
    },
    {
      "title": "API Endpoint Reference",
      "purpose": "Detailed API reference for every REST endpoint with request/response JSON schemas: GET / (service info, version, docs links), GET /health (available analyzers), POST /scan (ScanRequest: skill_path, policy, use_behavioral, use_llm, etc.), POST /scan-upload (multipart ZIP upload with query params), POST /scan-batch (BatchScanRequest for background batch), GET /scan-batch/{scan_id} (status: pending/running/completed/failed with results), GET /analyzers (capabilities list). Include curl and httpx examples. Reference skill_scanner/api/router.py, skill_scanner/api/api.py.",
      "parent": "Reference"
    },
    {
      "title": "Output Formats",
      "purpose": "Documentation of all five output reporters with example output for each: (1) Summary (default) — colored console with severity indicators, finding details, remediation advice; (2) JSON — full schema with findings array, compact mode with --compact; (3) Markdown — table-based report with severity, category, description, evidence; (4) Table — ASCII table for terminal display; (5) SARIF 2.1.0 — GitHub Code Scanning compatible, how to upload with github/codeql-action/upload-sarif. Reference skill_scanner/core/reporters/.",
      "parent": "Reference"
    },
    {
      "title": "Dependencies and LLM Providers",
      "purpose": "Complete dependency documentation: core dependencies (FastAPI, Pydantic v2, PyYAML, python-frontmatter, yara-x, httpx, click, rich, textual), dev dependencies (pytest, pytest-asyncio, ruff, mypy). LLM provider setup guide for each of the 7 supported providers: Anthropic Claude (anthropic SDK), OpenAI GPT (openai SDK), LiteLLM (unified 100+ models), Google GenAI (google-generativeai), AWS Bedrock (boto3, [bedrock] extra), GCP Vertex AI (google-cloud-aiplatform, [vertex] extra), Azure OpenAI (azure-identity, [azure] extra). Installation extras syntax and version compatibility. Reference pyproject.toml.",
      "parent": "Reference"
    },
    {
      "title": "CLI Command Reference",
      "purpose": "Quick-reference for all CLI commands and flags in concise table format: skill-scanner scan (all flags with types and defaults), skill-scanner scan-all (--recursive, --check-overlap), skill-scanner list-analyzers, skill-scanner validate-rules (--rules-file), skill-scanner generate-policy (--preset, -o), skill-scanner configure-policy, skill-scanner-api (--host, --port, --reload), and skill-scanner-pre-commit (install, --severity, --skills-path, --all). Reference skill_scanner/cli/cli.py, skill_scanner/api/api_cli.py, skill_scanner/hooks/pre_commit.py.",
      "parent": "Reference"
    }
  ]
}
